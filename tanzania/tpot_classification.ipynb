{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying waterpoints with TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "train_df = pd.read_csv(f'{data_path}/train.csv', index_col='id').join(\n",
    "    pd.read_csv(f'{data_path}/train_labels.csv', index_col='id')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 40)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "    \n",
    "class LatLonImputer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.lga_latlon = {\n",
    "            'Bariadi': (-2.807838, 33.988149),\n",
    "            'Geita': (-2.878836, 32.227321),\n",
    "            'Magu': (-2.591117, 33.439851),\n",
    "        }\n",
    "        \n",
    "    def transform(self, df, y=None):\n",
    "        X = df.copy()\n",
    "        mask = X.longitude < 20\n",
    "        for lga in X[mask].lga.unique():\n",
    "            assert lga in self.lga_latlon, f'unknown lga: {lga}'\n",
    "            lat, lon = self.lga_latlon[lga]\n",
    "            X.loc[mask & (X.lga == lga), 'latitude'] = lat\n",
    "            X.loc[mask & (X.lga == lga), 'longitude'] = lon\n",
    "        return X\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NanStringImputer(TransformerMixin):\n",
    "    \n",
    "    def transform(self, df, y=None):\n",
    "        X = df.copy()\n",
    "        obj_cols = [col for col, dtype in df.dtypes.items() if dtype == 'object']\n",
    "        for col in obj_cols:\n",
    "            X.loc[X[col].isna(), col] = 'nan'\n",
    "        return X\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\n",
    "    'latitude', 'longitude', 'gps_height',\n",
    "    'population', 'amount_tsh',\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'funder', 'installer',\n",
    "    'basin', 'subvillage', 'region', 'lga', 'ward',\n",
    "    'public_meeting', 'permit',\n",
    "    'extraction_type', 'extraction_type_group', 'extraction_type_class',\n",
    "    'payment', 'payment_type',\n",
    "    'water_quality',\n",
    "    'quality_group', 'quantity', 'quantity_group',\n",
    "    'source', 'source_type', 'source_class',\n",
    "    'waterpoint_type', 'waterpoint_type_group',\n",
    "]\n",
    "\n",
    "features = num_features + cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OrdinalEncoder\n",
    "\n",
    "feature_pipeline = make_pipeline(\n",
    "    LatLonImputer(),\n",
    "    NanStringImputer(),\n",
    "    ColumnTransformer([\n",
    "        (\"cat_features\", OrdinalEncoder(), cat_features),\n",
    "    ], remainder='passthrough')\n",
    ")\n",
    "\n",
    "target_encoder = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = feature_pipeline.fit_transform(train_df[features])\n",
    "train_target = target_encoder.fit_transform(train_df.status_group.values).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, train_target,\n",
    "                                                    train_size=0.8, test_size=0.2)\n",
    "\n",
    "pipeline_optimizer = TPOTClassifier(\n",
    "    generations=5,\n",
    "    population_size=64, \n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    memory='auto',\n",
    "    scoring='accuracy',\n",
    "    verbosity=5,\n",
    "    warm_start=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took about 3 hours...\n",
    "```python\n",
    "pipeline_optimizer.fit(X_train, y_train)\n",
    "print(pipeline_optimizer.score(X_test, y_test))\n",
    "pipeline_optimizer.export('tpot_exported_pipeline.py')\n",
    "```\n",
    "\n",
    "Here's what we copied from `tpot_exported_pipeline.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "# Average CV score on the training set was: 0.8047558922558922\n",
    "exported_pipeline = make_pipeline(\n",
    "    RobustScaler(),\n",
    "    RandomForestClassifier(\n",
    "        bootstrap=False, \n",
    "        criterion=\"entropy\", \n",
    "        max_features=0.5, \n",
    "        min_samples_leaf=8, \n",
    "        min_samples_split=2, \n",
    "        n_estimators=100\n",
    "    )\n",
    ")\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'randomforestclassifier__bootstrap': [False],\n",
    "    'randomforestclassifier__criterion': ['entropy'],\n",
    "    'randomforestclassifier__max_features': [0.5],\n",
    "    'randomforestclassifier__min_samples_leaf': [6, 8],\n",
    "    'randomforestclassifier__min_samples_split': [2],\n",
    "    'randomforestclassifier__n_estimators': [100, 160, 180],\n",
    "}\n",
    "results = GridSearchCV(\n",
    "    estimator=exported_pipeline, \n",
    "    param_grid=params, \n",
    "    scoring='accuracy',\n",
    "    cv=4,\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    ").fit(X=train_features, y=train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8072558922558923"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestclassifier__bootstrap': False,\n",
       " 'randomforestclassifier__criterion': 'entropy',\n",
       " 'randomforestclassifier__max_features': 0.5,\n",
       " 'randomforestclassifier__min_samples_leaf': 6,\n",
       " 'randomforestclassifier__min_samples_split': 2,\n",
       " 'randomforestclassifier__n_estimators': 160}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('robustscaler', RobustScaler()),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(bootstrap=False, criterion='entropy',\n",
       "                                        max_features=0.5, min_samples_leaf=6,\n",
       "                                        n_estimators=160))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    RobustScaler(),\n",
    "    RandomForestClassifier(\n",
    "        bootstrap=False, \n",
    "        criterion=\"entropy\", \n",
    "        max_features=0.5, \n",
    "        min_samples_leaf=6, \n",
    "        min_samples_split=2, \n",
    "        n_estimators=160\n",
    "    )\n",
    ")\n",
    "\n",
    "model.fit(X=train_features, y=train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f'{data_path}/test.csv')\n",
    "\n",
    "test_features = feature_pipeline.transform(test_df[features])\n",
    "\n",
    "index = test_df.id.values\n",
    "test_target = target_encoder.inverse_transform(model.predict(test_features)).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': index, 'status_group': test_target}).set_index('id')\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50785</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51630</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17168</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45559</th>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49871</th>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         status_group\n",
       "id                   \n",
       "50785  non functional\n",
       "51630      functional\n",
       "17168      functional\n",
       "45559  non functional\n",
       "49871      functional"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
